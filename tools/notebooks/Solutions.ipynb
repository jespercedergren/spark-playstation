{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b10eb9",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30219746",
   "metadata": {},
   "source": [
    "To see how many players of each rank are playing each level we have we can use the following query (group by Rank instead of selecting)\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(*) as num_players\n",
    "FROM players\n",
    "JOIN levels ON (players.Level_ID = levels.Level_ID)\n",
    "GROUP BY Rank, Level_Name;\n",
    "```\n",
    "\n",
    "A note on using `COUNT`:\n",
    " - Assumes that the players table is distinct, in particular that there is only one record of a player for a given combination of rank, level_id.\n",
    " - If assumption does not hold we would have to replace `COUNT` with `COUNT(DISTINCT Player_Id)`.\n",
    "\n",
    "If we further assume that there is a 1:1 mapping between `Level_ID:LevelName` we could get the result without the join using\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(*) as num_players\n",
    "FROM players\n",
    "GROUP BY Rank, Level_Id;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99296c1a",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f865326",
   "metadata": {},
   "source": [
    "The linux command downloads using from the second field (tab delimited) for every second row of the first 100 lines in a file.  \n",
    "\n",
    "However, it iteratively reads a larger and larger chunk of the file to only use the last line of that chunk.\n",
    "\n",
    "It would be preferable to be interact with the file once by specifying which rows and fields to access.\n",
    "\n",
    "This can be done in other ways, e.g. using the following one liner:  \n",
    "\n",
    "```bash\n",
    "awk 'NR % 2 == 0 && NR <= 100 {print $2}' filename | xargs -n1 wget -c 2> /dev/null\n",
    "````\n",
    "\n",
    "Using xargs -n1 ensures that each invocation of wget only takes 1 argument. The invocation is repeatedly executed until standard input is exhausted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324496ff",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e836b4",
   "metadata": {},
   "source": [
    "For the purpose of this exercies, it is crucial that each artist and track name can be uniquely identified. \n",
    "Deviations would cause the calculations to provide wrong values. If that assumption would not hold, an initial cleaning step would have to be added to the pipeline in this application.\n",
    "\n",
    "It was found that the artist id and track id columns contained null values, so the artist name and track name columns are used instead. \n",
    "The calculations below assume that the data is cleaned and standardized so that each track name and artist has a unique value, e.g. the artist `The Postal Service` and track `Such Great Heights` is not represented in the data in any other shape or form, such as in lower case or with extra spaces etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5377966",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(\"spark.master\", \"local\")\\\n",
    "    .appName(\"playstation\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a1730b",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "636dd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_songs = spark.read.parquet(\"../tests/resources/data/output/distinct_songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "239891dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|     userid|distinct_song_count|\n",
      "+-----------+-------------------+\n",
      "|user_000066|                666|\n",
      "|user_000113|               2133|\n",
      "|user_000098|                254|\n",
      "|user_000372|               4789|\n",
      "|user_000424|               2004|\n",
      "|user_000577|              18227|\n",
      "|user_000708|               4743|\n",
      "|user_000289|                994|\n",
      "|user_000319|               6294|\n",
      "|user_000445|               3718|\n",
      "|user_000794|               5743|\n",
      "|user_000339|               2522|\n",
      "|user_000821|               1878|\n",
      "|user_000171|                433|\n",
      "|user_000182|               9843|\n",
      "|user_000465|               1440|\n",
      "|user_000534|               3904|\n",
      "|user_000706|               4164|\n",
      "|user_000801|               2761|\n",
      "|user_000984|               1647|\n",
      "+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_songs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d7635a",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a39f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_songs_df = spark.read.parquet(\"../tests/resources/data/output/most_popular_songs\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654630e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+\n",
      "|        artist_name|          track_name|count|\n",
      "+-------------------+--------------------+-----+\n",
      "| The Postal Service|  Such Great Heights| 3992|\n",
      "|       Boy Division|Love Will Tear Us...| 3663|\n",
      "|          Radiohead|        Karma Police| 3534|\n",
      "|               Muse|Supermassive Blac...| 3483|\n",
      "|Death Cab For Cutie|     Soul Meets Body| 3479|\n",
      "|          The Knife|          Heartbeats| 3156|\n",
      "|               Muse|           Starlight| 3060|\n",
      "|        Arcade Fire|    Rebellion (Lies)| 3048|\n",
      "|     Britney Spears|          Gimme More| 3004|\n",
      "|        The Killers| When You Were Young| 2998|\n",
      "|           Interpol|                Evil| 2989|\n",
      "|         Kanye West|       Love Lockdown| 2950|\n",
      "|     Massive Attack|            Teardrop| 2948|\n",
      "|Death Cab For Cutie|I Will Follow You...| 2947|\n",
      "|               Muse| Time Is Running Out| 2945|\n",
      "|         Bloc Party|             Banquet| 2906|\n",
      "|        Arcade Fire|Neighborhood #1 (...| 2826|\n",
      "|          Radiohead|          All I Need| 2696|\n",
      "| The Postal Service|      Nothing Better| 2670|\n",
      "|        Snow Patrol|        Chasing Cars| 2667|\n",
      "+-------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_popular_songs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1fe9b6",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1319235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user_sessions_df = spark.read.parquet(\"../tests/resources/data/output/top_user_sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2248815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+---------------------+--------------------+\n",
      "|     userid|session_start_timestamp|session_end_timestamp|        sorted_songs|\n",
      "+-----------+-----------------------+---------------------+--------------------+\n",
      "|user_000949|    2006-02-12 17:49:31|  2006-02-27 11:29:37|[Chained To You, ...|\n",
      "|user_000997|    2007-04-26 00:36:02|  2007-05-10 17:55:03|[Unentitled State...|\n",
      "|user_000949|    2007-05-01 02:41:15|  2007-05-14 00:05:52|[White Daisy Pass...|\n",
      "|user_000544|    2007-02-12 13:03:52|  2007-02-23 00:51:08|[Finally Woken, O...|\n",
      "|user_000949|    2005-12-09 08:26:38|  2005-12-18 04:40:04|[Neighborhood #2 ...|\n",
      "|user_000949|    2005-11-11 03:30:37|  2005-11-18 22:50:07|[Excuse Me Miss A...|\n",
      "|user_000949|    2006-03-18 23:04:14|  2006-03-26 18:13:45|[Disco Science, H...|\n",
      "|user_000544|    2007-01-06 01:07:04|  2007-01-13 13:57:45|[La Murga, Breath...|\n",
      "|user_000250|    2008-02-21 15:31:45|  2008-02-28 21:18:03|[Lazarus Heart, S...|\n",
      "|user_000949|    2006-02-27 17:47:28|  2006-03-06 19:52:35|[Y-Control, Banqu...|\n",
      "+-----------+-----------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_user_sessions_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
